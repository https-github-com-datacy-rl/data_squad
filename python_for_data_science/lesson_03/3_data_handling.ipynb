{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6620680d-69c4-4f95-b249-e2cfb8a0446f",
   "metadata": {},
   "source": [
    "# Data Handling with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348fb5af-2d27-4811-8848-85960aa74f44",
   "metadata": {},
   "source": [
    "Handling data effectively is a core skill in data science and Python provides powerful tools for loading, processing, and transforming data. \n",
    "Here's an overview of how you can handle data with Python using libraries like Pandas and NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da12ac2-e9bb-4f3f-bb1b-30696f106363",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition\n",
    "- Data Sources: Data can come from various sources like files (CSV, Excel), databases (SQL), or live data streams (APIs).\n",
    "- Loading Data: Tools like Pandas provide functions to easily load data from these sources into Python for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f9b53-c168-40b8-905f-ada53a8fa06e",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "- Handling Missing Data: Real-world data often comes with missing or null values. Techniques include filling missing values with a specific value, average or median, or removing rows or columns with missing values.\n",
    "- Data Type Conversion: Ensuring that each column in the dataset is of the correct data type (numeric, string, datetime, etc.).\n",
    "- Removing Duplicates: Identifying and removing duplicate records from the data to avoid skewed analysis.\n",
    "- Renaming and Reordering: Renaming columns for better readability and reordering columns to organize the data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224278b3-855f-4fe4-9563-30772597887b",
   "metadata": {},
   "source": [
    "## 3. Data Transformation\n",
    "- Filtering: Selecting a subset of the entire dataset based on certain criteria.\n",
    "- Feature Engineering: Deriving new features from existing data to improve model performance or gain deeper insights.\n",
    "- Aggregation: Summarizing data, like finding the mean, median, or sum of a column, or grouping data based on certain categories.\n",
    "- Normalization and Standardization: Scaling numerical data to a standard range or distribution, often essential before applying machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fca945-80c7-46b8-a820-c4f726522f2b",
   "metadata": {},
   "source": [
    "## 4. Data Analysis\n",
    "- Statistical Analysis: Applying statistical techniques to understand relationships between variables, test hypotheses, and identify patterns and trends.\n",
    "- Correlation Analysis: Understanding the strength and direction of relationships between numerical variables.\n",
    "- Time Series Analysis: Analyzing time-stamped data to understand temporal patterns, trends, or to forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd106f4-4842-43b3-9215-f3421ed34ea7",
   "metadata": {},
   "source": [
    "## 5. Data Visualization\n",
    "- Charts and Plots: Creating visual representations of data (like line plots, scatter plots, histograms, etc.) to understand distributions, trends, and relationships between variables.\n",
    "- Advanced Visualization: Building more complex visualizations like heatmaps, pair plots, or geographic maps for in-depth analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138df272-6a00-4026-bcbf-31bec9bc22ff",
   "metadata": {},
   "source": [
    "## 6. Data Output/Export\n",
    "- Exporting Data: After analysis, cleaned or transformed data can be exported back to a file or database for further use or reporting.\n",
    "- Reporting: Tools like Jupyter Notebooks or Python scripts can be used to create reports or dashboards that include both the analysis and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3495b-5efc-4f11-a270-ac5fd67e78d7",
   "metadata": {},
   "source": [
    "Data handling with Python is a comprehensive process involving data acquisition, cleaning, transformation, analysis, visualization, and output. Libraries like Pandas and NumPy simplify these tasks, providing powerful and efficient tools for data manipulation and analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b56c2-b572-4c2e-86bc-81ce5610a617",
   "metadata": {},
   "source": [
    "## Pandas for Data Handling\n",
    "Pandas is an open-source library providing high-performance, easy-to-use data structures, and data analysis tools for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c8bcd6-3d1e-4122-af0d-584dc0a2c559",
   "metadata": {},
   "source": [
    "### Installation\n",
    "If you haven't installed Pandas, you can do so using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f8386-725a-4b14-a51a-51149913c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a65a3b-aae6-4da5-a35f-1735ae7fd6e6",
   "metadata": {},
   "source": [
    "### Basic Data Structures\n",
    "Pandas has two primary data structures:\n",
    "\n",
    "**Series**: A one-dimensional labeled array capable of holding any data type.\n",
    "**DataFrame**: A two-dimensional labeled data structure with columns that can be of different types.\n",
    "### Reading Data\n",
    "Pandas can read data from various file formats like CSV, Excel, JSON, SQL, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d181ea-d2e1-4b9a-a64c-556be876984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV file\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Read data from Excel file\n",
    "df = pd.read_excel('data.xlsx')\n",
    "\n",
    "# Show the first 5 rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9014d-a03b-4ac2-8725-adf21db651cc",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Pandas offers extensive capabilities to prepare your data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44274356-4f0f-4e90-9d89-4a700acd634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Fill missing values with a default value\n",
    "df = df.fillna(value=0)\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2cfae2-552b-439e-8582-6bce91fcc1c0",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "Pandas provides numerous functions to transform and manipulate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42a076-fddc-4608-a559-e6e23f04b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a function to a column\n",
    "df['column'] = df['column'].apply(lambda x: x + 10)\n",
    "\n",
    "# Group data\n",
    "grouped = df.groupby('column_name')\n",
    "\n",
    "# Merge DataFrames\n",
    "merged_df = pd.merge(df1, df2, on='key_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6754b7-0e23-483f-87b2-86672428edf0",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "Pandas allows for comprehensive data analysis with just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee9501-2cdc-4c1d-ada7-1e325637b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Correlation matrix\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75753d-448f-45c0-9f8f-9a41ac12a8a3",
   "metadata": {},
   "source": [
    "## NumPy for Numerical Data\n",
    "NumPy is the fundamental package for scientific computing in Python. It provides a high-performance multidimensional array object and tools for working with arrays.\n",
    "\n",
    "###Basic NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e185ba52-455b-4b15-87c8-fbce855005c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "print(a)\n",
    "\n",
    "# Create an array of zeros\n",
    "zeros = np.zeros((2, 3))\n",
    "\n",
    "# Create an array of ones\n",
    "ones = np.ones((2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb83085-a8fb-443b-b9d5-ee915e42b6bc",
   "metadata": {},
   "source": [
    "### Operations with NumPy Arrays\n",
    "NumPy offers a variety of operations for numerical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3171c423-2b31-4b63-8d31-529cff7331e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6]\n",
      "[1 4 9]\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise addition\n",
    "print(a + a)\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(a * a)\n",
    "\n",
    "# Matrix multiplication\n",
    "a2 = np.array([[1, 2], [3, 4]])\n",
    "b2 = np.array([[5, 6], [7, 8]])\n",
    "print(np.dot(a2, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4dc03d-1ec5-418f-819d-ac699e8d84c6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- Pandas is excellent for structured data operations and analysis and is often used for loading, cleaning, transforming, and analyzing data.\n",
    "- NumPy is ideal for numerical operations on arrays and matrices, offering a powerful and efficient way to handle numerical data.\n",
    "Both Pandas and NumPy are foundational libraries for data handling in Python, and mastering them is crucial for any data-related task, from simple data munging and cleaning to complex data analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c197a6-65bb-4c29-bab3-7b1bd0a6ac8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_eng]",
   "language": "python",
   "name": "conda-env-data_eng-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
