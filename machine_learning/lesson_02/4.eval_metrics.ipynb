{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efdcf56b-e2fe-4777-8f76-033a9295bd66",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26b196-0a8e-4187-9b1a-0342e0d0fd19",
   "metadata": {},
   "source": [
    "Evaluation metrics are crucial for assessing the performance of machine learning models. They help in determining how well a model is performing in terms of making predictions for both classification and regression tasks. Here's an overview of the key metrics used for each type of task:\n",
    "\n",
    "#### Evaluation Metrics for Classification\n",
    "1. Accuracy:\n",
    "\n",
    "- The ratio of correctly predicted instances to the total instances.\n",
    "- Accuracy = NumberÂ ofÂ CorrectÂ Predictions/TotalÂ NumberÂ ofÂ Predictions\n",
    "2. Precision (Positive Predictive Value):\n",
    "\n",
    "- The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "- Precision = TP / (TP + FP)\n",
    "- Important when the cost of False Positives is high (e.g., spam detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded4fec-477d-442f-8d69-a6a2c585947e",
   "metadata": {},
   "source": [
    "3. Recall (Sensitivity, Hit Rate, or True Positive Rate):\n",
    "\n",
    "- The ratio of correctly predicted positive observations to all observations in actual class.\n",
    "Recall\n",
    "=\n",
    "TP\n",
    "TP\n",
    "+\n",
    "FN\n",
    "Recall= \n",
    "TP+FN\n",
    "TP\n",
    "â€‹\n",
    " \n",
    "Important when the cost of False Negatives is high (e.g., fraud detection).\n",
    "4. F1 Score (Harmonic Mean of Precision and Recall):\n",
    "\n",
    "The weighted average of Precision and Recall.\n",
    "F1Â Score\n",
    "=\n",
    "2\n",
    "Ã—\n",
    "Precision\n",
    "Ã—\n",
    "Recall\n",
    "Precision\n",
    "+\n",
    "Recall\n",
    "F1Â Score=2Ã— \n",
    "Precision+Recall\n",
    "PrecisionÃ—Recall\n",
    "â€‹\n",
    " \n",
    "Useful when you seek a balance between Precision and Recall.\n",
    "5. Confusion Matrix:\n",
    "\n",
    "A table used to describe the performance of a classification model.\n",
    "Shows TP (True Positives), TN (True Negatives), FP (False Positives), and FN (False Negatives).\n",
    "6. ROC (Receiver Operating Characteristic) Curve:\n",
    "\n",
    "- A graphical representation of the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "7. AUC (Area Under the ROC Curve):\n",
    "\n",
    "- A measure of the ability of a classifier to distinguish between classes.\n",
    "- Higher AUC indicates a better performing model.\n",
    "#### Evaluation Metrics for Regression\n",
    "1. Mean Absolute Error (MAE):\n",
    "\n",
    "The mean of the absolute values of the individual prediction errors on over all instances in the test set.\n",
    "MAE\n",
    "=\n",
    "1\n",
    "ğ‘›\n",
    "âˆ‘\n",
    "ğ‘–\n",
    "=\n",
    "1\n",
    "ğ‘›\n",
    "âˆ£\n",
    "ğ‘¦\n",
    "ğ‘–\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    "âˆ£\n",
    "MAE= \n",
    "n\n",
    "1\n",
    "â€‹\n",
    " âˆ‘ \n",
    "i=1\n",
    "n\n",
    "â€‹\n",
    " âˆ£y \n",
    "i\n",
    "â€‹\n",
    " âˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " âˆ£\n",
    "Represents average error.\n",
    "Mean Squared Error (MSE):\n",
    "\n",
    "The mean of the squared differences between the actual and the predicted values.\n",
    "MSE\n",
    "=\n",
    "1\n",
    "ğ‘›\n",
    "âˆ‘\n",
    "ğ‘–\n",
    "=\n",
    "1\n",
    "ğ‘›\n",
    "(\n",
    "ğ‘¦\n",
    "ğ‘–\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    ")\n",
    "2\n",
    "MSE= \n",
    "n\n",
    "1\n",
    "â€‹\n",
    " âˆ‘ \n",
    "i=1\n",
    "n\n",
    "â€‹\n",
    " (y \n",
    "i\n",
    "â€‹\n",
    " âˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " ) \n",
    "2\n",
    " \n",
    "More sensitive to outliers than MAE.\n",
    "Root Mean Squared Error (RMSE):\n",
    "\n",
    "The square root of the MSE.\n",
    "RMSE\n",
    "=\n",
    "1\n",
    "ğ‘›\n",
    "âˆ‘\n",
    "ğ‘–\n",
    "=\n",
    "1\n",
    "ğ‘›\n",
    "(\n",
    "ğ‘¦\n",
    "ğ‘–\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "^\n",
    "ğ‘–\n",
    ")\n",
    "2\n",
    "RMSE= \n",
    "n\n",
    "1\n",
    "â€‹\n",
    " âˆ‘ \n",
    "i=1\n",
    "n\n",
    "â€‹\n",
    " (y \n",
    "i\n",
    "â€‹\n",
    " âˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " ) \n",
    "2\n",
    " \n",
    "â€‹\n",
    " \n",
    "More commonly used than MSE as it's in the same units as the response variable.\n",
    "R-squared (Coefficient of Determination):\n",
    "\n",
    "The proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "ğ‘…\n",
    "2\n",
    "=\n",
    "1\n",
    "âˆ’\n",
    "SumÂ ofÂ SquaresÂ ofÂ Residuals\n",
    "TotalÂ SumÂ ofÂ Squares\n",
    "R \n",
    "2\n",
    " =1âˆ’ \n",
    "TotalÂ SumÂ ofÂ Squares\n",
    "SumÂ ofÂ SquaresÂ ofÂ Residuals\n",
    "â€‹\n",
    " \n",
    "Indicates how well the regression predictions approximate the real data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36921913-eff3-4afc-aeb5-4f40469aa729",
   "metadata": {},
   "source": [
    "5. Adjusted R-squared:\n",
    "\n",
    "- Adjusted R-squared considers the number of predictors in the model and adjusts the R-squared accordingly.\n",
    "- More useful than R-squared when comparing models with different numbers of predictors.\n",
    "\n",
    "Choosing the right evaluation metric is crucial as it influences how the performance of a machine learning model is measured and compared. These metrics provide insights into areas that require improvement and help in selecting the model that best fits the business needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577eddc2-3a02-4b55-8d02-b735052024a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_eng]",
   "language": "python",
   "name": "conda-env-data_eng-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
